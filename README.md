# Automating an ETL Pipeline via Apache Airflow

## Prerequisites for the project
- You must be able to use Python and a form of SQL
- For the sake of containing Apache Airflow, knowledge and the installation of Docker is recommended
- Apache Airflow to allow the process of automation to be fulfilled
- **To avoid your system crashing or moving at a snail's pace, it is highly recommended your system has more than 8 Gigabytes of RAM allocation! Apache Airflow is highly intensive, it will be using a lot of your memory!**

Please also note, this guide is following the process for setting up ETL automation under Linux (specifically an Ubuntu-based operating system). If you are using a different version of Linux or a completely different operating sysstem (I am extremely sorry if you have Windows 11), some parts of this guide may not be suitable for your system. I will try to allocate some notes for changes that may be present on your OS, but I may miss some problems that I am not familiar with (macOS is an area I am particularly weak in, apologies again - though for different reasons compared to Windows 11. I mean at least your OS works and doesn't rot, but I'm getting sidetracked).
